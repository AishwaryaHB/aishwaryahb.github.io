### About Me

I am a PhD candidate in <a href="https://www.ece.gatech.edu/" target="_blank">Electrical & Computer Engineering</a> at <a href="https://www.gatech.edu/" target="_blank">Georgia Tech</a>, largely interested in characterizing learning and intelligence in artificial and biological systems. Towards these ends, I spend my time studying both machine learning and theoretical + computational neuroscience, with a healthy smattering of many topics in applied mathematics.
I am primarily advised by <a href="https://hannahchoi.math.gatech.edu/people/about-hannah-choi/" target="_blank">Dr. Hannah Choi</a> and co-advised by <a href="https://siplab.gatech.edu/rozell.html" target="_blank">Dr. Chris Rozell</a>. 

<!--
I'm associated with the <a href="https://ml.gatech.edu/" target="_blank">ML@GT</a> and <a href="https://neuro.gatech.edu/" target="_blank">GT Neuro</a> research communities, and have previously worked closely with <a href="https://bme.gatech.edu/bme/faculty/Eva-Dyer" target="_blank">Dr. Eva Dyer</a>.
-->

### Ongoing Research

<!--Much of my proposed work revolves around and studies different aspects of <a href="https://arxiv.org/abs/1206.5538" target="_blank">representation learning</a> with an eye towards  explaining complex, hierarchical information processing systems.-->
My research broadly leverages structure (geometrical and topological) in the representations and architectures of _artificial & biological_ neural networks so as to render them more interpretable and thereby discover their governing principles.
Some ideas that I actively think about in these contexts are:
- Sparse, low-rank, and low-dimensional approximations of data.
- The effects of regularization & architecture on representations learnt by neural networks.
- Disentangling of data manifolds, the quantification of representations that live on them, their evolution across space-time, and the changes that different perturbations bring about in them.
- Generalizability and potential for transfer of representations across different tasks and domains.

My long-term goals of understanding learning + intelligence combined with my facility for math & engineering have led to the following (somewhat) more tangible goals that I try to actively contribute to with my research:
- Development of mathematical models and computational methods that effectively characterize as well as elucidate changes in structure, organization, and information processing in deep neural networks and the brain across different stages of development.
- Development of "better" ML/AI systems that require less supervision and/or data, learn progressively, and are more amenable to changes in task structure (along with supporting foundational theory or guarantees whenever possible!)
- Tackling AI Alignment from first principles, i.e., trying to fundamentally ensure deep learning models as and when deployed, do what we want/intend for them to do (relatively recent foray!)

### Recent-ish News
- **February 2025:** I am being supported by Open Philanthropy's <a href="https://www.openphilanthropy.org/career-development-and-transition-funding/" target="_blank">Career Development & Transition Funding</a> through Spring '25 as I upskill in AI Safety and Alignment. Thanks, <a href="https://www.openphilanthropy.org/" target="_blank">Open Phil</a>!
- **February 2025:** I've successfully defended my PhD! My thesis is titled <a href="https://bit.ly/aish-dissertation-defense" target="_blank">_Through the RNN Looking Glass: Structure-Function Relationships in Cortical Circuits for Predictive Coding_</a>, and the dissertation <a href="https://bit.ly/aish-dissertation-doc" target="_blank">document</a>, <a href="https://bit.ly/aish-dissertation-defense" target="_blank">defense talk</a>, as well as <a href="https://bit.ly/aish-dissertation-slides" target="_blank">slides</a> are all accessible online!
- **January 2025:** The <a href="https://www.biorxiv.org/content/10.1101/2025.01.09.632231v1" target="_blank">preprint</a> of our paper on incorporating anatomical constraints in RNNs for neuroscientific applications is up on bioRxiv!
- **December 2024:** Our work on <a href="https://hchoilab.github.io/biologicalRNNs/" target="_blank">constructing biologically-constrained RNNs that respect Dale's law while incorporating sparse connectivity motifs</a> has been accepted to COSYNE 2025! 
-  **May 2024:** The <a href="https://www.biorxiv.org/content/10.1101/2024.05.23.595629v1/" target="_blank">preprint</a> of our work studying the <a href="https://hchoilab.github.io/corticalRNN/" target="_blank">architectural biases of the canoncial cortical microcircuit</a> is now up on bioRxiv! This work was also highlighted as a <a href="https://www.youtube.com/live/0eSzx_cvqJU?feature=share&t=3930" target="_blank">talk</a> at <a href="https://www.cosyne.org/" target="_blank">COSYNE '23</a> in Montr√©al!
- **July 2022:** Our paper on leveraging <a href="https://arxiv.org/abs/2206.06563" target="_blank">persistent homology to theoretically explain the empirical successes of iterative magnitude pruning</a> has been accepted to the <a href="https://icml.cc/virtual/2022/workshop/13447" target="_blank">TAG in ML</a> workshop at ICML 2022, with a <a href="https://icml.cc/virtual/2022/20798" target="_blank">spotlight presentation</a>! It will be published in the PMLR volume _Topology, Algebra, and Geometry in Learning_, and is also being presented at the <a href="https://www.sparseneural.net/" target="_blank">Sparsity in Neural Networks Workshop 2022</a>. This work is a joint effort with my good friend, <a href="https://github.com/JakobKrzyston" target="_blank">Jakob Krzyston</a>.

<!--
Recent news archives:
- June 2022: I will be spending my summer in NYC at the Flatiron Institute's <a href="https://www.simonsfoundation.org/flatiron/center-for-computational-neuroscience/" target="_blank">Center for Computational Neuroscience</a>, working with <a href="https://sites.google.com/site/sueyeonchung/" target="_blank">Dr. SueYeon Chung</a>!
- October 2021: New preprint on <a href="https://arxiv.org/abs/2110.08447" target="_blank">detecting attacks on DNNs</a> using robust statistics up on arXiv! Joint work with <a href="https://www.linkedin.com/in/chandramouli-amarnath-40285a117" target="_blank">Chandramouli Amarnath</a>.
- July 2021: I had a great time participating in the <a href="https://www.logml.ai/" target="_blank">London Geometry and Machine Learning Summer School</a> and studying the topological properties of deep autoencoders  with <a href="https://kellyspendlove.github.io/" target="_blank">Dr. Kelly Spendlove</a> and co.
- June 2021: Our paper on multi-task learning for <a href="/docs/papers/ICIP_2021___XRay_MTL.pdf" target="_blank">multi-scale modelling of neural structure</a> in X-ray imagery will be appearing at <a href="https://2021.ieeeicip.org/Papers/AcceptedPapers.asp" target="_blank">ICIP 2021</a>!
- March 2021: I led a mini-project titled <a href="/docs/papers/CAB_First_Project.pdf" target="_blank">Modeling Visual Invariance with Symmetry Regularization</a> as part of my coursework for <a href="http://computationandbrain.wordpress.com/" target="_blank">Computation and the Brain</a>. Code (hopefully) coming soon!
- December 2020: I proposed and my committee said yes! The <a href="https://docs.google.com/presentation/d/1CwdIcPrBHtIGCnvnLMVvNSehDLcfvrzMZlBzTPdyTfA/edit#slide=id.gaf67c39d40_0_0" target="_blank">slides</a> of my talk are publicly accessible.
- October 2020: Our paper, "<a href="https://www.nature.com/articles/s41597-020-00692-y" target="_blank">A three-dimensional thalamocortical dataset for characterizing brain heterogeneity</a>" is now up in <a href = "https://www.nature.com/sdata/" target="_blank">Nature Scientific Data</a>! You can also take a look at our publicly available <a href="http://bossdb.org/project/prasad2020" target="_blank">dataset</a>.
- July 2020: We presented a <a href="/docs/papers/Balwani_ICML_Interpretability_Workshop_2020.pdf" target="_blank">4-pg version</a> of Deep Brain Discovery at the <a href="https://sites.google.com/view/mli4sd-icml2020/program?authuser=0#h.fyakn5jvpae2" target="_blank">ML Interpretability for Scientific Discovery</a> workshop at <a href="https://icml.cc/" target="_blank">ICML 2020</a>! I was also in attendance at the main conference and tutorials as a recipient of the ICML Diversity and Inclusion Fellowship. 
- June 2020: Our paper, "<a href="https://www.biorxiv.org/content/10.1101/2020.06.04.134635v1.abstract" target="_blank">A generative modeling approach for interpreting population-level variability in brain structure</a>" has been accepted to <a href="https://www.miccai2020.org/en/" target="_blank">MICCAI 2020</a>! Code and data are available <a href="https://nerdslab.github.io/brainsynth/" target="_blank">here</a>.
- May 2020: Our <a href="https://www.biorxiv.org/content/10.1101/2020.05.26.117473v1" target="_blank">preprint</a> on discovery of microstructure in brain imagery using deep learning, a.k.a <a href="https://nerdslab.github.io/deepbraindisco/" target="_blank">DeepBrainDisco</a> is is now up on bioRxiv!
- October 2020: I had the opportunity to serve as a <a href="https://tda-in-ml.github.io/committee" target="_blank">reviewer</a> for the <a href="https://tda-in-ml.github.io/" target="_blank">Topological Data Analysis and Beyond</a> workshop at <a href="https://nips.cc/Conferences/2020/" target="_blank">NeurIPS 2020</a>. The <a href="https://openreview.net/group?id=NeurIPS.cc/2020/Workshop/TDA_and_Beyond#all-submissions" target="_blank">papers submitted</a> were (in my humble opinion) of very high quality and some of the most novel and exciting work I've seen.
- April 2020: I served as a reviewer for the <a href="https://sites.google.com/view/clvision2020" target="_blank">Workshop on Continual Learning in Computer Vision</a> at CVPR 2020.
- June 2020: I volunteered as a content reviewer at <a href="https://neuromatch.io/academy/" target="_blank">Neuromatch Academy 2020</a>.
- June 2020: I served as a reviewer for the <a href="https://lifelongml.github.io/" target="_blank">Lifelong Learning Workshop</a> at ICML 2020.
- November 2019: I had the pleasure of attending the Banach Center - Oberwolfach Graduate Seminar on <a href="https://www.mfo.de/occasion/1947a" target="_blank">Mathematics of Deep Learning</a> in Pozna≈Ñ, Poland!
- November 2019: We presented our work, "<a href="https://ieeexplore.ieee.org/document/9048805" target="_blank">Modeling variability in brain architecture with deep feature learning</a>" at Asilomar 2019 in the Deep Learning & Neuroscience session!
- October 2019: Our review article on <a href="https://www.sciencedirect.com/science/article/pii/S2468451119300625" target="_blank">brain mapping at high resolutions</a> is out in COBME!
- October 2019: I contributed to 2 extended abstracts presented at <a href="https://alleninstitute.org/media/filer_public/38/be/38be5b2f-e678-45c0-9608-069116238488/bioimage2019_fullprogram_asof96.pdf" target="_blank">BioImage Informatics 2019</a> in Seattle, WA.
-->

### Interests & Hobbies

**Machine Learning:** Unsupervised/self-supervised learning, dimensionality reduction & manifold learning, metric/similarity learning, and learning with structured sparsity.<br>
**Mathematics:** Matrix & tensor decompositions, column subset selection, low-rank approximation, metric embeddings, convex geometry, optimization, group & representation theory, differential geometry & topology, and information geometry.<br>
**Neuroscience:** Neural (i.e., population and sparse) coding, predictive coding, synaptic plasticity & learning rules, models of brain structure & organization, and connectomics.

Outside of academic and scientific pursuits, my hobbies include reading üìñ, listening to + studying classical music üéº, watching + playing racquet sports üéæ, trying (and often failing) to keep up with cool movies + TV shows üé•, and solving every Rubik's cube variant üé≤ I can get my hands on.

I am incredibly fond of cats üêà, enjoy history of almost any kind üìú, still identify as an ardent Federer fan üíú, and remain a Bombay kid üåèüè†üë∂ at heart for life. üåà.

<!--
### Curriculum Vitae
<p float="left">
<a href="https://bit.ly/3bTpPf2"><img src="/images/cv_logo_clipart_bg_trans.png" height="60" width="60" /></a>
</p>
-->

### Social Network
<p float="left">
<a href="https://scholar.google.com/citations?user=wyXqxjwAAAAJ&hl=en" target="_blank"><img src="/images/google-scholar-logo.png" height="30" width="30" /></a>
<a href="https://github.com/AishwaryaHB" target="_blank"><img src="/images/GitHub-logo-crop.png" height="30" width="30" /></a>
<a href="https://twitter.com/Iishiiyaa" target="_blank"><img src="/images/twitter-logo-2.png" height="30" width="30" /></a>
<a href="https://www.linkedin.com/in/aishwaryahb" target="_blank"><img src="/images/linkedin-logo-2.png" height="30" width="30" /></a>
<a href="https://www.facebook.com/aishvarrya/" target="_blank"><img src="/images/facebook-logo-2019.png" height="30" width="30" /></a>
<a href="https://www.instagram.com/iishiiyaa/" target="_blank"><img src="/images/Instagram-LOGO-MPC-circle.png" height="30" width="30" /></a>
</p>
